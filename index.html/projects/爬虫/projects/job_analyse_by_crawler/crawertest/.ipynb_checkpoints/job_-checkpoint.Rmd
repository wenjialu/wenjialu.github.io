---
title: "Untitled"
author: "wenjia"
date: "2020/6/16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
x = c('rvest','RCurl','stringr','httr','tidyverse')
lapply(x,require,character.only=TRUE)
```

# create url
```{r}
url = "https://www.lagou.com/jobs/list_%E6%95%B0%E6%8D%AE%E5%AE%9E%E4%B9%A0/p-city_3?&cl=false&fromSearch=true&labelWords=&suginput="
#https://www.zhipin.com/c101020100/?query=%E6%95%B0%E6%8D%AE%E5%AE%9E%E4%B9%A0&ka=sel-city-101020100

```
# get web data
```{r}
headers = c('User-Agent'='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.61 Safari/537.36',
'cookie'='RECOMMEND_TIP=true; _ga=GA1.2.10707914.1589273745; user_trace_token=20200512165453-1261ab7a-edcb-4bf7-849d-cd0aef1ee5e7; LGUID=20200512165453-c9ffb47d-0a75-410a-97f9-44372671b6e0; sensorsdata2015jssdkcross=%7B%22distinct_id%22%3A%2217208191c54706-0e27e5c76dc665-396d7500-1296000-17208191c557f4%22%2C%22%24device_id%22%3A%2217208191c54706-0e27e5c76dc665-396d7500-1296000-17208191c557f4%22%7D; LG_LOGIN_USER_ID=e599b97ca91ffd98597e3f5fc6a69355f7ced9f236b081eb600526abc60e95b4; LG_HAS_LOGIN=1; JSESSIONID=ABAAAECABIEACCA5A35857C057631E6CD73DAD030638AE7; WEBTJ-ID=20200616174653-172bc863c09db-04fe54018a3ed-1b3a6251-1296000-172bc863c0a142; PRE_UTM=; PRE_LAND=https%3A%2F%2Fwww.lagou.com%2F; _gid=GA1.2.1114061038.1592300815; Hm_lvt_4233e74dff0ae5bd0a3d81c6ccf756e6=1592300815; LGSID=20200616174638-cbe9e5e7-e2b2-494e-acc3-be56ef507bc3; PRE_HOST=www.google.com; PRE_SITE=https%3A%2F%2Fwww.google.com%2F; index_location_city=%E4%B8%8A%E6%B5%B7; _gat=1; SEARCH_ID=84861fecdac142758601672015c423a8; X_HTTP_TOKEN=96217b0cfd18c95d26800329513a681ffbf14c120e; Hm_lpvt_4233e74dff0ae5bd0a3d81c6ccf756e6=1592300879; TG-TRACK-CODE=search_code; LGRID=20200616175631-b02ff5d8-af68-4cca-a82c-e4f0f879f144
')




webcode = GET(url)
              #,add_headers(.headers =headers))
              #,encode="json",verbose())
  
```
# create data frame
# 构建一个空数据框，然后通过load命令把所有数据导入R，接着通过rvest的read_html命令读取网页的所有节点，并通过管道函数%>%连接另一个命令html_nodes 抽取想要的节点，最后通过html_text命令得到想要的文本信息。



```{r}
webdata = data.frame()

job = read_html(webcode)%>%html_text()
# job_title = read_html(url)%>% html_nodes('.job-name a')%>%html_text()
#company= read_html(url)%>%html_nodes('h3.name')%>%html_text()
#salary = read_html(url)%>%html_nodes('span.red')%>%html_text()
#
#webdata = rbind(webdata,data.frame(job))

job

```


```{r}
 
  job_title = read_html(webcode)%>%html_nodes('.job-name')%>%html_text()
    salary = read_html(webcode)%>%html_nodes('span.red')%>%html_text()
    company= read_html(webcode)%>%html_nodes('h3.name')%>%html_text()
```

```{r}

```


  comment_num = read_html(webcode)%>%html_nodes('span.threadlist_rep_num.center_text')%>%html_text()
  lastcom = read_html(webcode)%>%html_nodes('.j_reply_data')%>%html_text()%>%str_extract_all('\\d+[:|-]\\d+')%>%unlist()
  lastcom = gsub('\\d+:\\d+','5-31',lastcom)
  webdata = rbind(webdata,data.frame(comment_num,title,lastcom,stringsAsFactors = FALSE) )
