---
title: "Untitled"
author: "wenjia"
date: "2020/6/16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 前期下载工具

```{r}
x = c('rvest','RCurl','stringr','httr','tidyverse')
lapply(x,require,character.only=TRUE)
```

# 爬虫主要思路：分四步

# 第一步 获取网站信息 



# create url
```{r}
url ='http://zh.zhhlzzs.com/CN/0254-1769/current.shtml'
```
# get web data
```{r}

webcode2 = GET(url)
# webcode =  RETRY("GET", url[k])
#Sys.sleep(runif(1,2,3))
#save(webcode,file = paste0("job",k,".Rdata"))

```
# 第二步 转换数据


# create data frame
# 构建一个空数据框，然后通过load命令把所有数据导入R，接着通过rvest的read_html命令读取网页的所有节点，并通过管道函数%>%连接另一个命令html_nodes 抽取想要的节点，最后通过html_text命令得到想要的文本信息。




```{r}

#
title = read_html(webcode2) 
#%>%html_nodes('.MsoNormal a')%>%html_text()

#webdata = rbind(webdata,data.frame(job,stringsAsFactors = FALSE))

title
```


```{r}
 
  job_title = read_html(webcode)%>%html_nodes('div.job-name')%>%html_text()
    salary = read_html(webcode)%>%html_nodes('span.red')%>%html_text()
    company= read_html(webcode)%>%html_nodes('h3.name')%>%html_text()
```

```{r}

```


  comment_num = read_html(webcode)%>%html_nodes('span.threadlist_rep_num.center_text')%>%html_text()
  lastcom = read_html(webcode)%>%html_nodes('.j_reply_data')%>%html_text()%>%str_extract_all('\\d+[:|-]\\d+')%>%unlist()
  lastcom = gsub('\\d+:\\d+','5-31',lastcom)
  webdata = rbind(webdata,data.frame(comment_num,title,lastcom,stringsAsFactors = FALSE) )
