---
title: "Untitled"
author: "wenjia"
date: "2020/6/16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 前期下载工具

```{r}
x = c('rvest','RCurl','stringr','httr','tidyverse')
lapply(x,require,character.only=TRUE)
```

# 爬虫主要思路：分四大步

# 第一步 获取网站信息 



# create url
```{r}
url ='http://zh.zhhlzzs.com/CN/0254-1769/current.shtml'
```
# get web data
```{r}

webcode = GET(url)
# webcode =  RETRY("GET", url[k])
#Sys.sleep(runif(1,2,3))
#save(webcode,file = paste0("job",k,".Rdata"))

```
# 第二步 转换数据


# 第三步 提取数据 ⭐️（根据网站结构，选取想要的节点）


# create data frame
# 构建一个空数据框，然后通过load命令把所有数据导入R，接着通过rvest的read_html命令读取网页的所有节点，并通过管道函数%>%连接另一个命令html_nodes 抽取想要的节点，最后通过html_text命令得到想要的文本信息。




```{r}

#可以分步骤读取转换后的数据

title = read_html(webcode) 

title
```


```{r}
 #也可以通过管道函数一步到位
webdata= {}
title = read_html(webcode)%>%html_nodes('div.job-name')%>%html_text()
salary = read_html(webcode)%>%html_nodes('span.red')%>%html_text()
company= read_html(webcode)%>%html_nodes('h3.name')%>%html_text()
webdata = rbind(webdata,data.frame(title,salary,company,stringsAsFactors = FALSE) )
}
```

# 第四步 保存


```{r}
save(webdata,file = information.csv)
```

  
