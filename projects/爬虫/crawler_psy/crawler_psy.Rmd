---
title: "crawler_psy"
author: "wenjia"
date: "2020/5/22"
output: html_document
---
#前言：
#目的：本研究拟爬取心理吧前100页的标题和评论数来探究人们对心理学的态度。

#load package
```{r}
x = c('rvest','stringr','httr','tmcn','qdap','Rwordseg',
'tm','plyr','wordcloud2','tidyverse','Ismeans')
lapply(x,require,character.only=TRUE)
```
```{r}
#nlp中比较难装的包
#install.packages("tmcn") #直接本地下了tmcn和Rwordseg
# install.packages("tmcn", repos = "http://R-Forge.R-project.org", type = "source")
#https://r-forge.r-project.org/R/?group_id=1571
Sys.setenv(JAVA_HOME="/Applications/Java")
#/Applications/Java /Applications/Java/JavaVirtualMachines/jdk-14.0.1.jdk 

install.packages("rJava")  #Rwordseg的依赖 
# The downloaded binary packages are in
#	/var/folders/1q/ljzws8x17qb10dkhny9245tr0000gn/T//RtmpEg2JMK/downloaded_packages
?rJava
install.packages("Rwordseg")
library(tmcn)
library(Rwordseg)
```

# create url
```{r}
urlp = "https://tieba.baidu.com/f?kw=心理学&ie=utf-8&pn="
url = c()
for (i in 0:100){
  page = i*50 
  url = c(paste0(urlp,page),url)}
url
```
# get web data
```{r}
for (k in 1:100){
  webcode = GET(url[k])
  # webcode =  RETRY("GET", url[k])
  Sys.sleep(runif(1,2,3))
  save(webcode,file = paste0("web",k,".Rdata"))
}
```
# create data frame
# 构建一个空数据框，然后通过load命令把所有数据导入R，接着通过rvest的read_html命令读取网页的所有节点，并通过管道函数%>%连接另一个命令html_nodes 抽取想要的节点，最后通过html_text命令得到想要的文本信息。


```{r}
a = load("web3.Rdata")
```

```{r}
webdata = data.frame()
for (i in 1:100){
  load(paste0("web",i,".Rdata"))
  title = read_html(webcode)%>%html_nodes('a.j_th_tit')%>%html_text()
  comment_num = read_html(webcode)%>%html_nodes('span.threadlist_rep_num.center_text')%>%html_text()
  lastcom = read_html(webcode)%>%html_nodes('.j_reply_data')%>%html_text()%>%str_extract_all('\\d+[:|-]\\d+')%>%unlist()
  lastcom = gsub('\\d+:\\d+','5-31',lastcom)
  webdata = rbind(webdata,data.frame(comment_num,title,lastcom,stringsAsFactors = FALSE) )
}
head(webdata)
```

# 语料处理
## 台湾大学发布的中文情感词典作为情绪语料库（ L.-W. Ku, Y.-T. Liang, &H. H. Chen 2006）
```{r}
#demo to use package tmcn
# data(GBK)
# head(GBK)
```

```{r}

data(NTUSD)
# head(NTUSD)
positive = NTUSD[[1]] #通过tmcn拉取情绪语料库
negative = NTUSD[[2]]
insertWords(positive) #给中文分词，把积极词汇分为一个词
insertWords(nagetive)
transfer_senten1 = segmentCN(webdata$title,returnType = "vector")
head(transfer_senten1)
```

# 使用自定义函数（抄自知乎，见Reference）对每个标题进行逐个积极消极情感打分。其算法的核心为对所有标题的分词进行积极和消极词库的匹配，每当有一个词匹配成功两个词库任意一个中的一个词就加一分，一个标题可能包含多个积极和消极词汇，通过积极词汇和消极词汇得分之差是否大于0来判断该句子为积极和消极。
例如，一个句子有三个积极词汇两个消极词汇。那么这个句子的总情绪得分为3-2=1，故为积极标题。若得分为0，则将标题归为中性标题。之后再合并整个数据框。具体代码如下：
```{r}
fun = function(x,y) x%in%y
getEmotionalType = function(x,pwords,nwords){
  pos.weight = sapply(llply(x,fun,positive),sum)
  neg.weight = sapply(llply(x,fun,negative),sum)
  total = pos.weight - neg.weight
  return(data.frame(pos.weight,neg.weight,total))
}

###################caculate sentiment score
score = getEmotionalType(transfer_senten1,positive,negative)
sentiment_data = data.frame(webdata$title,score,webdata$comment_num)%>%
  mutate(valence-case_when(
    total>0~"Pos",
    total<0~"Neg",
    TRUE ~ "Neu"
  ))

```

#结果分析
```{r}
#
kk = table(sentiment_data$valence)%>%as.data.frame()
ggplot(kk, aes(x=Var1,y=Freq))+
  geom_bar(stat = "identity")+
  geom_text(data = kk, aes(y=Freq,label=Freq),vjust=-0.5)
```
